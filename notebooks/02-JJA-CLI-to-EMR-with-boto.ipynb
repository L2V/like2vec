{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will take the CLI commands produced in `01-JJA-L2V-Configuration-Files` notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ You need to install aws cli    \n",
    "http://docs.aws.amazon.com/cli/latest/userguide/installing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ You need to run** `aws config` **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the functions defined before for loading parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from load_config import params_to_cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    llr, emb, pred,evaluation = params_to_cli(\"CONFIGS/ex1-ml-1m-config.yml\", \"CONFIGS/ex4-du04d100w10l80n10d30p1q1-1000-081417-params.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark-submit --deploy-mode cluster --class llr.LLR s3://sandbox-l2v/JARs/llr-assembly-1.2.jar --master yarn --options default --useroritem user --threshold 0.4 --interactionsFile s3://sandbox-l2v/datasets/ml-1m/split/split-cleaned-formatted-4and5/ml1m-train-clean4and5 --outputFile s3://sandbox-l2v/datasets/ml-1m/llr_output/llr12-081417-du04 --separator \",\" --maxInteractionsPerUserOrItem 500 --seed 12345'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark-submit --deploy-mode cluster --class eval --master yarn s3://sandbox-l2v/JARs/evaluation-assembly-1.5.jar --options allMetrics --inputFile s3://sandbox-l2v/datasets/ml-1m/predictions/du04-d100w10l80n10d30-p1q1-1000-081417/part-00000 --outputFile s3://sandbox-l2v/datasets/ml-1m/eval/du04-d100w10l80n10d30-p1q1-1000-081417'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will format the AWS CLI commands so we can pass them to the cluster using `boto3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_steps(llr=None, emb=None, pred=None, evaluation=None, name=''):\n",
    "    if llr != None:\n",
    "        Steps=[\n",
    "\n",
    "        {\n",
    "            'Name': name + '-LLR',\n",
    "            'ActionOnFailure': 'CONTINUE',\n",
    "            'HadoopJarStep': {\n",
    "                'Jar': 'command-runner.jar',\n",
    "                'Args': (llr).split(),\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'Name': name + '-EMB',\n",
    "            'ActionOnFailure': 'CONTINUE',\n",
    "            'HadoopJarStep': {\n",
    "                'Jar': 'command-runner.jar',\n",
    "                'Args': (emb).split(),\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'Name': name + '-PRED',\n",
    "            'ActionOnFailure': 'CONTINUE',\n",
    "            'HadoopJarStep': {\n",
    "                'Jar': 'command-runner.jar',\n",
    "                'Args': (pred).split(),\n",
    "            }\n",
    "        },\n",
    "            {\n",
    "            'Name': name + '-EVAL',\n",
    "            'ActionOnFailure': 'CONTINUE',\n",
    "            'HadoopJarStep': {\n",
    "                'Jar': 'command-runner.jar',\n",
    "                'Args': (evaluation).split(),\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    else:\n",
    "        Steps=[\n",
    "        {\n",
    "            'Name': name + '-EMB',\n",
    "            'ActionOnFailure': 'CONTINUE',\n",
    "            'HadoopJarStep': {\n",
    "                'Jar': 'command-runner.jar',\n",
    "                'Args': (emb).split(),\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'Name': name + '-PRED',\n",
    "            'ActionOnFailure': 'CONTINUE',\n",
    "            'HadoopJarStep': {\n",
    "                'Jar': 'command-runner.jar',\n",
    "                'Args': (pred).split(),\n",
    "            }\n",
    "        },\n",
    "            {\n",
    "            'Name': name + '-EVAL',\n",
    "            'ActionOnFailure': 'CONTINUE',\n",
    "            'HadoopJarStep': {\n",
    "                'Jar': 'command-runner.jar',\n",
    "                'Args': (evaluation).split(),\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "                     \n",
    "            \n",
    "    return Steps\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the commands into EMR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create steps based on the three steps in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ex2 = create_steps(llr=llr, emb=emb, pred=pred, evaluation=evaluation, name='EXP3')\n",
    "ex3 = create_steps(llr=llr, emb=emb, pred=pred, evaluation=evaluation, name='EXP3')\n",
    "# ex4 = create_steps(emb=emb348, pred=pred348, name='EXP4')\n",
    "# ex5 = create_steps(emb=emb349, pred=pred349, name='EXP5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are adding multiple runs of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# steps = ex2 + ex3 + ex4 + ex5\n",
    "steps = ex3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ActionOnFailure': 'CONTINUE',\n",
       "  'HadoopJarStep': {'Args': ['spark-submit',\n",
       "    '--deploy-mode',\n",
       "    'cluster',\n",
       "    '--class',\n",
       "    'llr.LLR',\n",
       "    's3://sandbox-l2v/JARs/llr-assembly-1.2.jar',\n",
       "    '--master',\n",
       "    'yarn',\n",
       "    '--options',\n",
       "    'default',\n",
       "    '--useroritem',\n",
       "    'user',\n",
       "    '--threshold',\n",
       "    '0.4',\n",
       "    '--interactionsFile',\n",
       "    's3://sandbox-l2v/datasets/ml-1m/split/split-cleaned-formatted-4and5/ml1m-train-clean4and5',\n",
       "    '--outputFile',\n",
       "    's3://sandbox-l2v/datasets/ml-1m/llr_output/llr12-081417-du04',\n",
       "    '--separator',\n",
       "    '\",\"',\n",
       "    '--maxInteractionsPerUserOrItem',\n",
       "    '500',\n",
       "    '--seed',\n",
       "    '12345'],\n",
       "   'Jar': 'command-runner.jar'},\n",
       "  'Name': 'EXP3-LLR'},\n",
       " {'ActionOnFailure': 'CONTINUE',\n",
       "  'HadoopJarStep': {'Args': ['spark-submit',\n",
       "    '--deploy-mode',\n",
       "    'cluster',\n",
       "    '--class',\n",
       "    'Main',\n",
       "    's3://sandbox-l2v/JARs/n2v-assembly-3.7.jar',\n",
       "    '--dim',\n",
       "    '100',\n",
       "    '--window',\n",
       "    '10',\n",
       "    '--walkLength',\n",
       "    '80',\n",
       "    '--numWalks',\n",
       "    '10',\n",
       "    '--degree',\n",
       "    '30',\n",
       "    '--p',\n",
       "    '1',\n",
       "    '--q',\n",
       "    '1',\n",
       "    '--weighted',\n",
       "    'true',\n",
       "    '--directed',\n",
       "    'false',\n",
       "    '--indexed',\n",
       "    'true',\n",
       "    '--input',\n",
       "    's3://sandbox-l2v/datasets/ml-1m/llr_output/llr12-081417-du04/part-00000',\n",
       "    '--output',\n",
       "    's3://sandbox-l2v/datasets/ml-1m/network-embeddings/embeddings37-du04-081417-d100w10l80n10d30-p1q1',\n",
       "    '--cmd',\n",
       "    'node2vec'],\n",
       "   'Jar': 'command-runner.jar'},\n",
       "  'Name': 'EXP3-EMB'},\n",
       " {'ActionOnFailure': 'CONTINUE',\n",
       "  'HadoopJarStep': {'Args': ['spark-submit',\n",
       "    '--deploy-mode',\n",
       "    'cluster',\n",
       "    '--class',\n",
       "    'Prediction',\n",
       "    '--master',\n",
       "    'yarn-cluster',\n",
       "    's3://sandbox-l2v/JARs/prediction-assembly-2.2.jar',\n",
       "    '--dim',\n",
       "    '100',\n",
       "    '--ntype',\n",
       "    'KNN',\n",
       "    '--train',\n",
       "    's3://sandbox-l2v/datasets/ml-1m/split/split-cleaned-formatted-4and5/ml1m-train-clean4and5',\n",
       "    '--test',\n",
       "    's3://sandbox-l2v/datasets/ml-1m/split/split-cleaned-formatted/ml1m-validation-clean',\n",
       "    '--embedding',\n",
       "    's3://sandbox-l2v/datasets/ml-1m/network-embeddings/embeddings37-du04-081417-d100w10l80n10d30-p1q1.emb/part-00000',\n",
       "    '--neighbors',\n",
       "    '1000',\n",
       "    '--rmse',\n",
       "    's3://sandbox-l2v/datasets/ml-1m/rmse/du04-d100w10l80n10d30-p1q1-1000-081417',\n",
       "    '--predictions',\n",
       "    's3://sandbox-l2v/datasets/ml-1m/predictions/du04-d100w10l80n10d30-p1q1-1000-081417'],\n",
       "   'Jar': 'command-runner.jar'},\n",
       "  'Name': 'EXP3-PRED'},\n",
       " {'ActionOnFailure': 'CONTINUE',\n",
       "  'HadoopJarStep': {'Args': ['spark-submit',\n",
       "    '--deploy-mode',\n",
       "    'cluster',\n",
       "    '--class',\n",
       "    'eval',\n",
       "    '--master',\n",
       "    'yarn',\n",
       "    's3://sandbox-l2v/JARs/evaluation-assembly-1.5.jar',\n",
       "    '--options',\n",
       "    'allMetrics',\n",
       "    '--inputFile',\n",
       "    's3://sandbox-l2v/datasets/ml-1m/predictions/du04-d100w10l80n10d30-p1q1-1000-081417/part-00000',\n",
       "    '--outputFile',\n",
       "    's3://sandbox-l2v/datasets/ml-1m/eval/du04-d100w10l80n10d30-p1q1-1000-081417'],\n",
       "   'Jar': 'command-runner.jar'},\n",
       "  'Name': 'EXP3-EVAL'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the steps into EMR using boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = boto3.client('emr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_id = 'j-2JGJ9RIFQ4VRK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = client.add_job_flow_steps(\n",
    "    JobFlowId = cluster_id,\n",
    "    Steps= steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'HTTPHeaders': {'content-length': '85',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Mon, 14 Aug 2017 23:05:18 GMT',\n",
       "   'x-amzn-requestid': '0a786bd8-8145-11e7-8dd1-d31bf82860c5'},\n",
       "  'HTTPStatusCode': 200,\n",
       "  'RequestId': '0a786bd8-8145-11e7-8dd1-d31bf82860c5',\n",
       "  'RetryAttempts': 0},\n",
       " 'StepIds': ['s-1AN2B0U2UFIX9',\n",
       "  's-2C0ZF4PO9CFPP',\n",
       "  's-380HRBF5JCHJI',\n",
       "  's-22VTB7A3XMKDZ']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
